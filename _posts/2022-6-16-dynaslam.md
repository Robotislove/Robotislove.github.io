---
layout: post
title: åŠ¨æ€ç¯å¢ƒä¸‹SLAMå­¦ä¹ ç¬”è®°æ±‡æ€»
date: 2022-06-16
author: lau
tags: [åŠ¨æ€SLAM, Archive]
comments: true
toc: false
pinned: false
---
åŠ¨æ€ç¯å¢ƒSLAMæ˜¯ç›®å‰slamæ–¹å‘çš„ä¸€ä¸ªçƒ­é—¨ç ”ç©¶é¢†åŸŸã€‚

<!-- more -->

## Related survey papers:

- [**A survey: which features are required for dynamic visual simultaneous localization and mapping?**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8285453/pdf/42492_2021_Article_86.pdf). Zewen Xu,CAS. 2021
- [**State of the Art in Real-time Registration of RGB-D Images**](https://cg.cs.uni-bonn.de/aigaion2root/attachments/StateoftheArtinReal-timeRegistrationofRGB-DImages.pdf). Stotko, Patrick. University of Bonn. 2016
- [**Visual SLAM and Structure from Motion in Dynamic Environments: A Survey**](https://dl.acm.org/doi/pdf/10.1145/3177853).  University of Oxford. 2018
- [**State of the Art on 3D Reconstruction with RGB-D Cameras**](https://www.cg.informatik.uni-siegen.de/data/Publications/2018/star1009-main.pdf). Michael ZollhÃ¶fer. Stanford University. 2018
## Related Article:

- https://www.zhihu.com/question/47817909
- [deeplabv3+ slam](https://www.shangyexinzhi.com/article/4766362.html)
- [SOF-SLAMï¼šä¸€ç§é¢å‘åŠ¨æ€ç¯å¢ƒçš„è¯­ä¹‰è§†è§‰SLAMï¼ˆ2019ï¼ŒJCR Q1ï¼Œ 4.076ï¼‰](https://blog.csdn.net/ainitutu/article/details/107540299)
## ä¸­æ–‡å·¥ä½œæ±‡æ€»

- 1.DynaSLAMï¼ˆIROS 2018ï¼‰
  - è®ºæ–‡ï¼šDynaSLAM: Tracking, Mapping and Inpainting in Dynamic Scenes
  ä»£ç ï¼šhttps://github.com/BertaBescos/DynaSLAM
  ä¸»è¦æ€æƒ³ï¼šï¼ˆè¯­ä¹‰+å‡ ä½•ï¼‰
  1.ä½¿ç”¨Mask-CNNè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼›
  2.åœ¨low-cost Trackingé˜¶æ®µå°†åŠ¨æ€åŒºåŸŸï¼ˆäººï¼‰å‰”é™¤ï¼Œå¾—åˆ°åˆå§‹ä½å§¿ï¼›
  3.å¤šè§†å›¾å‡ ä½•æ–¹æ³•åˆ¤æ–­å¤–ç‚¹ï¼Œé€šè¿‡åŒºåŸŸå¢é•¿æ³•ç”ŸæˆåŠ¨æ€åŒºåŸŸï¼›
  4.ä»£ç ä¸­å°†å¤šè§†å›¾å‡ ä½•çš„åŠ¨æ€åŒºåŸŸä¸è¯­ä¹‰åˆ†å‰²äººçš„åŒºåŸŸå…¨éƒ½å»é™¤ï¼Œå°†maskä¼ ç»™orbslamè¿›è¡Œè·Ÿè¸ªï¼›
  5.èƒŒæ™¯ä¿®å¤ï¼ŒåŒ…æ‹¬RGBå›¾å’Œæ·±åº¦å›¾ã€‚
  **åˆ›æ–°ç‚¹ï¼š** è¯­ä¹‰åˆ†å‰²æ— æ³•è¯†åˆ«ç§»åŠ¨çš„æ¤…å­ï¼Œéœ€è¦å¤šè§†å›¾å‡ ä½•çš„æ–¹æ³•è¿›è¡Œè¡¥å……
  **è®¨è®ºï¼š** DynaSLAMä¸ä¸‹é¢çš„DS-SLAMæ˜¯ç»å…¸çš„åŠ¨æ€slamç³»ç»Ÿï¼Œä»£ç å®ç°éƒ½å¾ˆç®€æ´ã€‚Dyna-SLAMçš„ç¼ºç‚¹åœ¨äºï¼š1.å¤šè§†å›¾å‡ ä½•æ–¹æ³•å¾—åˆ°çš„å¤–ç‚¹ï¼Œåœ¨æ·±åº¦å›¾ä¸Šé€šè¿‡åŒºåŸŸå¢é•¿å¾—åˆ°åŠ¨æ€åŒºåŸŸï¼Œåªè¦ç‰©ä½“ä¸Šå­˜åœ¨ä¸€ä¸ªåŠ¨æ€ç‚¹ï¼Œæ•´ä¸ªç‰©ä½“éƒ½ä¼šè¢«â€œå¢é•¿â€æˆä¸ºåŠ¨æ€ 2.å…¶å°†äººçš„åŒºåŸŸä»¥åŠå¤šè§†å›¾å‡ ä½•æ–¹æ³•å¾—åˆ°çš„åŒºåŸŸéƒ½ç›´æ¥å»æ‰ï¼Œä¸è®ºæ–‡ä¸ç¬¦ã€‚
  ![](https://img-blog.csdnimg.cn/20210530120315904.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  ![](https://img-blog.csdnimg.cn/20210530120328187.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 2.DS-SLAMï¼ˆIROS 2018ï¼Œ æ¸…åå¤§å­¦ï¼‰
  - è®ºæ–‡ï¼šDS-SLAM: A Semantic Visual SLAM towards Dynamic Environments

ä»£ç ï¼šhttps://github.com/ivipsourcecode/DS-SLAM
ä¸»è¦æ€æƒ³ï¼šï¼ˆè¯­ä¹‰+å‡ ä½•ï¼‰
1.SegNetè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼ˆå•ç‹¬ä¸€ä¸ªçº¿ç¨‹ï¼‰ï¼›
2.å¯¹äºå‰åä¸¤å¸§å›¾åƒï¼Œé€šè¿‡æçº¿å‡ ä½•æ£€æµ‹å¤–ç‚¹ï¼›
3.å¦‚æœæŸä¸€ç‰©ä½“å¤–ç‚¹æ•°é‡è¿‡å¤šï¼Œåˆ™è®¤ä¸ºæ˜¯åŠ¨æ€ï¼Œå‰”é™¤ï¼›
4.å»ºç«‹äº†è¯­ä¹‰å…«å‰æ ‘åœ°å›¾ã€‚
è®¨è®ºï¼šè¿™ç§å››çº¿ç¨‹çš„ç»“æ„ä»¥åŠæçº¿çº¦æŸçš„å¤–ç‚¹æ£€æµ‹æ–¹æ³•å¾—åˆ°äº†å¾ˆå¤šè®ºæ–‡çš„é‡‡çº³ï¼Œå…¶ç¼ºç‚¹åœ¨äºï¼š1.æçº¿çº¦æŸçš„å¤–ç‚¹æ£€æµ‹æ–¹æ³•å¹¶ä¸èƒ½æ‰¾åˆ°æ‰€æœ‰å¤–ç‚¹ï¼Œå½“ç‰©ä½“æ²¿æçº¿æ–¹å‘è¿åŠ¨æ—¶è¿™ç§æ–¹æ³•ä¼šå¤±æ•ˆ 2.ç”¨ç‰¹å¾ç‚¹ä¸­çš„å¤–ç‚¹çš„æ¯”ä¾‹æ¥åˆ¤æ–­è¯¥ç‰©ä½“æ˜¯å¦è¿åŠ¨ï¼Œè¿™ç”¨æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œç‰¹å¾ç‚¹çš„æ•°é‡å—ç‰©ä½“çº¹ç†çš„å½±å“è¾ƒå¤§ 3.SegNetæ˜¯2016å¹´å‰”é™¤çš„è¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼Œåˆ†å‰²æ•ˆæœæœ‰å¾ˆå¤§æå‡ç©ºé—´ï¼Œå®éªŒæ•ˆæœä¸å¦‚Dyna-SLAM
![](https://img-blog.csdnimg.cn/20210530120144856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 3.Detect-SLAMï¼ˆ2018 IEEE WCACVï¼Œ åŒ—äº¬å¤§å­¦ï¼‰

è®ºæ–‡ï¼šDetect-SLAM: Making Object Detection and SLAM Mutually Beneficial
ä»£ç ï¼šhttps://github.com/liadbiz/detect-slam
ä¸»è¦æ€æƒ³ï¼š
ç›®æ ‡æ£€æµ‹çš„ç½‘ç»œå¹¶ä¸èƒ½å®æ—¶è¿è¡Œï¼Œæ‰€ä»¥åªåœ¨å…³é”®å¸§ä¸­è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œç„¶åé€šè¿‡ç‰¹å¾ç‚¹çš„ä¼ æ’­å°†å…¶ç»“æœä¼ æ’­åˆ°æ™®é€šå¸§ä¸­
1.åªåœ¨å…³é”®å¸§ä¸­ç”¨SSDç½‘ç»œè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼ˆå¾—åˆ°çš„æ˜¯çŸ©å½¢åŒºåŸŸåŠå…¶ç½®ä¿¡åº¦ï¼‰ï¼Œå›¾å‰²æ³•å‰”é™¤èƒŒæ™¯ï¼Œå¾—åˆ°æ›´åŠ ç²¾ç»†çš„åŠ¨æ€åŒºåŸŸï¼›
2.åœ¨æ™®é€šå¸§ä¸­ï¼Œåˆ©ç”¨feature matching + matching point expansionä¸¤ç§æœºåˆ¶ï¼Œå¯¹æ¯ä¸ªç‰¹å¾ç‚¹åŠ¨æ€æ¦‚ç‡ä¼ æ’­ï¼Œè‡³æ­¤å¾—åˆ°æ¯ä¸ªç‰¹å¾ç‚¹çš„åŠ¨æ€æ¦‚ç‡ï¼›
3.object mapå¸®åŠ©æå–å€™é€‰åŒºåŸŸã€‚

![](https://img-blog.csdnimg.cn/20210530120440760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 4.VDO-SLAMï¼ˆarXiv 2020ï¼‰

è®ºæ–‡ï¼šVDO-SLAM: A Visual Dynamic Object-aware SLAM System
ä»£ç ï¼š https://github.com/halajun/vdo_slam
ä¸»è¦æ€æƒ³ï¼š
1.è¿åŠ¨ç‰©ä½“è·Ÿè¸ªï¼Œæ¯”è¾ƒå…¨çš„slam+è¿åŠ¨è·Ÿè¸ªçš„ç³»ç»Ÿï¼›
2.å…‰æµ+è¯­ä¹‰åˆ†å‰²ã€‚
![](https://img-blog.csdnimg.cn/20210530120519434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 5.Co-Fusionï¼ˆICRA 2017ï¼‰

è®ºæ–‡ï¼šCo-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects
ä»£ç ï¼šhttps://github.com/martinruenz/co-fusion
**ä¸»è¦æ€æƒ³ï¼š** å­¦ä¹ å’Œç»´æŠ¤æ¯ä¸ªç‰©ä½“çš„3Dæ¨¡å‹ï¼Œå¹¶é€šè¿‡éšæ—¶é—´çš„èåˆæé«˜æ¨¡å‹ç»“æœã€‚è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ç³»ç»Ÿï¼Œå¾ˆå¤šè®ºæ–‡éƒ½æ‹¿å®ƒè¿›è¡Œå¯¹æ¯”
![](https://img-blog.csdnimg.cn/20210530120626236.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 6.Learning Rigidity in Dynamic Scenes with a Moving Camera for 3D Motion Field Estimationï¼ˆ2018ï¼ŒECCVï¼ŒNVIDIAï¼‰

è®ºæ–‡ï¼šLearning Rigidity in Dynamic Scenes with a Moving Camera for 3D Motion Field Estimation
ä»£ç ï¼šhttps://github.com/NVlabs/learningrigidity.git
ä¸»è¦æ€æƒ³ï¼š
1.RTNç½‘ç»œç”¨äºè®¡ç®—ä½å§¿ä»¥åŠåˆšä½“åŒºåŸŸï¼ŒPWCç½‘ç»œç”¨äºè®¡ç®—ç¨ å¯†å…‰æµï¼›
2.åŸºäºä»¥ä¸Šç»“æœï¼Œä¼°è®¡åˆšä½“åŒºåŸŸçš„ç›¸å¯¹ä½å§¿ï¼›
3.è®¡ç®—åˆšä½“çš„3Dåœºæ™¯æµï¼›
æ­¤å¤–è¿˜å¼€å‘äº†ä¸€å¥—ç”¨äºç”ŸæˆåŠäººå·¥åŠ¨æ€åœºæ™¯çš„å·¥å…·REFRESHã€‚

![](https://www.guyuehome.com//Uploads/Editor/202106/20210618_83839.jpg)

- 7.ReFusionï¼ˆ2019 IROSï¼‰

è®ºæ–‡ï¼šReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals

ä»£ç ï¼šhttps://github.com/PRBonn/refusion
ä¸»è¦æ€æƒ³ï¼š
ä¸»æµçš„åŠ¨æ€slamæ–¹æ³•éœ€è¦ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œåˆ†å®ä¾‹åˆ†å‰²ï¼Œæ­¤è¿‡ç¨‹éœ€è¦é¢„å…ˆå®šä¹‰å¯èƒ½åŠ¨æ€çš„å¯¹è±¡å¹¶åœ¨æ•°æ®é›†ä¸Šè¿›è¡Œå¤§é‡çš„è®­ç»ƒï¼Œä½¿ç”¨åœºæ™¯å—åˆ°å¾ˆå¤§çš„é™åˆ¶ã€‚è€ŒReFusionåˆ™ä½¿ç”¨çº¯å‡ ä½•çš„æ–¹æ³•åˆ†å‰²åŠ¨æ€åŒºåŸŸï¼Œå…·ä½“çš„ï¼šåœ¨KinectFusionç¨ å¯†slamç³»ç»Ÿçš„åŸºç¡€ä¸Šï¼Œè®¡ç®—æ¯ä¸ªåƒç´ ç‚¹çš„æ®‹å·®ï¼Œé€šè¿‡è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²å¾—åˆ°å¤§è‡´åŠ¨æ€åŒºåŸŸï¼Œå½¢æ€å­¦å¤„ç†å¾—åˆ°æœ€ç»ˆåŠ¨æ€åŒºåŸŸï¼Œä¸æ­¤åŒæ—¶ï¼Œå¯å¾—åˆ°é™æ€èƒŒæ™¯çš„TSDFåœ°å›¾ã€‚
è®¨è®ºï¼šä¸ºæ•°ä¸å¤šçš„ä¸ä½¿ç”¨ç¥ç»ç½‘ç»œçš„åŠ¨æ€slamç³»ç»Ÿ
![](https://www.guyuehome.com//Uploads/Editor/202106/20210618_48914.jpg)

- 8.RGB_D-SLAM-with-SWIAICPï¼ˆ2017ï¼‰

è®ºæ–‡ï¼šRGB-D SLAM in Dynamic Environments Using Static Point Weighting
ä»£ç ï¼šhttps://github.com/VitoLing/RGB_D-SLAM-with-SWIAICP
ä¸»è¦æ€æƒ³ï¼š
1.ä»…ä½¿ç”¨å‰æ™¯çš„è¾¹ç¼˜ç‚¹è¿›è¡Œè·Ÿè¸ªï¼ˆ Foreground Depth Edge Extractionï¼‰ï¼›
2.æ¯éš”nå¸§æ’å…¥å…³é”®å¸§ï¼Œé€šè¿‡å½“å‰å¸§ä¸å…³é”®å¸§è®¡ç®—ä½å§¿ï¼›
3.é€šè¿‡æŠ•å½±è¯¯å·®è®¡ç®—æ¯ä¸ªç‚¹äº‘çš„é™æ€-åŠ¨æ€è´¨é‡ï¼Œä¸ºä¸‹é¢çš„IAICPæä¾›æ¯ä¸ªç‚¹äº‘çš„æƒé‡ï¼›
4.æå‡ºäº†èåˆç°åº¦ä¿¡æ¯çš„ICPç®—æ³•â€“IAICPï¼Œç”¨äºè®¡ç®—å¸§ä¸å¸§ä¹‹é—´çš„ä½å§¿ã€‚
**è®¨è®ºï¼š** å‰æ™¯ç‰©ä½“çš„è¾¹ç¼˜ç‚¹èƒ½å¤Ÿå¾ˆå¥½åœ°è¡¨å¾æ•´ä¸ªç‰©ä½“ï¼Œå®éªŒæ•ˆæœä»¤äººè€³ç›®ä¸€æ–°ã€‚ä½†æ˜¯æ–‡ä¸­æ‰€ç”¨çš„ICPç®—æ³•è¿™å¹¶ä¸æ˜¯è¾¹ç¼˜slamå¸¸ç”¨çš„ç®—æ³•ï¼Œè¾¹ç¼˜slamä¸€èˆ¬ä½¿ç”¨è·ç¦»å˜æ¢ï¼ˆDTï¼‰æè¿°è¾¹ç¼˜ç‚¹çš„è¯¯å·®ï¼Œå…¶å¯ä»¥é¿å…ç‚¹ä¸ç‚¹ä¹‹é—´çš„åŒ¹é…ã€‚è®ºæ–‡Robust RGB-D visual odometry based on edges and pointsæå‡ºäº†ä¸€ç§å¾ˆæœ‰æ„æ€çš„æ–¹æ¡ˆï¼Œç”¨ç‰¹å¾ç‚¹è®¡ç®—ä½å§¿ï¼Œç”¨è¾¹ç¼˜ç‚¹æè¿°åŠ¨æ€åŒºåŸŸï¼Œå¾ˆå¥½åœ°æ±²å–äº†äºŒè€…çš„ä¼˜åŠ¿ã€‚

![](https://img-blog.csdnimg.cn/20210530120722763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpbnFpbnhpYW5zaGVuZw==,size_16,color_FFFFFF,t_70)

- 9.RDS-SLAMï¼ˆ2021ï¼ŒAccessï¼‰

è®ºæ–‡ï¼šRDS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods
ä»£ç ï¼šhttps://github.com/yubaoliu/RDS-SLAM.git
ä¸»è¦æ€æƒ³ï¼šå…‹æœä¸èƒ½å®æ—¶è¿›è¡Œè¯­ä¹‰åˆ†å‰²çš„é—®é¢˜
1.é€‰æ‹©æœ€è¿‘çš„å…³é”®å¸§è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼›
2.åŸºäºè´å¶æ–¯çš„æ¦‚ç‡ä¼ æ’­ï¼›
3.é€šè¿‡ä¸Šä¸€å¸§å’Œå±€éƒ¨åœ°å›¾å¾—åˆ°å½“å‰å¸§çš„å¤–ç‚¹ï¼›
4.æ ¹æ®è¿åŠ¨æ¦‚ç‡åŠ æƒè®¡ç®—ä½å§¿ã€‚

![](https://www.guyuehome.com//Uploads/Editor/202106/20210619_99878.jpg)

- é è°±çš„å·¥ä½œ
  - DS-SLAM Dynaslam:https://github.com/zhuhu00/DS-SLAM_modifyï¼› https://blog.csdn.net/qq_41623632/article/details/112911046ï¼›
## Dynamic Object Detection and *Removal*

- Pfreundschuh, Patrick, et al. â€œ**[Dynamic Object Aware LiDAR SLAM Based on Automatic Generation of Training Data.](http://arxiv.org/abs/2104.03657)**â€ (*ICRA* *2021*)
  - **ETH ASL**,code, [video](https://youtu.be/LcDxd97r1Gc), [**dataset**](https://projects.asl.ethz.ch/datasets/doals), Lidar
  - ä½œè€…åŸºäºdeep-learningï¼ˆ3D-MiniNetç½‘ç»œï¼‰è¿›è¡Œå®æ—¶3DåŠ¨æ€ç‰©ä½“æ£€æµ‹ï¼Œæ»¤é™¤åŠ¨æ€ç‰©ä½“åçš„ç‚¹äº‘è¢«å–‚ç»™LOAMï¼Œè¿›è¡Œå¸¸è§„çš„æ¿€å…‰SLAMã€‚æä¾›äº†å­¦ä¹ çš„æ–¹æ³•æ˜¯å±äºæ— ç›‘ç£çš„æ–¹æ³•ã€‚
  
- Canovas Bruce, et al. â€œ[**Speed and Memory Efficient Dense RGB-D SLAM in Dynamic Scenes.**](https://doi.org/10.1109/IROS45743.2020.9341542)â€ (*IROS* 2020)
  - **GIPSA-lab**, [code](https://github.com/BruceCanovas/supersurfel_fusion), [video](https://youtu.be/hzzVVHUAO74)
  
- Yuan Xun and Chen Song. â€œ[**SaD-SLAM: A Visual SLAM Based on Semantic and Depth Information.**](http://ras.papercept.net/images/temp/IROS/files/0092.pdf)â€ *(IROS 2020)*
  - **USTC**, code, video
  
- Dong, Erqun, et al. â€œ[**Pair-Navi: Peer-to-Peer Indoor Navigation with Mobile Visual SLAM.**](https://cswu.me/papers/infocom19_pairnavi.pdf)â€ (ICCC 2019)
  - Tsinghua, [Code](https://github.com/Horacehxw/Dynamic_ORB_SLAM2), Video, [Slides](https://slidetodoc.com/pairnavi-peertopeer-indoor-navigation-with-mobile-visual-slam/).
  
- Ji Tete, et al. â€œ**[Towards Real-Time Semantic RGB-D SLAM in Dynamic Environments](https://arxiv.org/abs/2104.01316v1)**.â€ (ICRA 2021)

- Palazzolo Emanuele, et al. â€œ**[ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals.](https://arxiv.org/abs/1905.02082v3)**â€ (IROS 2019)
  - [code](https://github.com/PRBonn/refusion),[video](https://youtu.be/1P9ZfIS5-p4).University of Bonn.
  
- Arora Mehul, et al. ***[Mapping the Static Parts of Dynamic Scenes from 3D LiDAR Point Clouds Exploiting Ground Segmentation](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/arora2021ecmr.pdf)***. p. 6.

- Chen Xieyuanli, et al. â€œ**[Moving Object Segmentation in 3D LiDAR Data: A Learning-Based Approach Exploiting Sequential Data](https://www.ipb.uni-bonn.de/pdfs/chen2021ral-iros.pdf)**.â€ *IEEE Robotics and Automation Letters*, 2021
  - [code](https://github.com/PRBonn/LiDAR-MOS). [video](https://www.youtube.com/watch?v=NHvsYhk4dhw). University of Bonn.
  
- Zhang Tianwei, et al. â€œ[**FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow.**](http://arxiv.org/abs/2003.05102.)â€(ICRA 2020)
  - code. [video](https://youtu.be/6yPGDdwKFLA).
  
- Zhang Tianwei, et al. â€œ**[AcousticFusion: Fusing Sound Source Localization to Visual SLAM in Dynamic Environments.](http://arxiv.org/abs/2108.01246)**â€,IROS 2021
  - [video](https://youtu.be/8eNikzp9LIQ). ç»“åˆå£°éŸ³ä¿¡å·
  
- 1. Liu Yubao and Miura Jun. â€œ[**RDS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods.**](https://doi.org/10.1109/ACCESS.2021.3050617)â€ *IEEE Access* 2021

  2. Liu Yubao and Miura Jun. â€œRDMO-SLAM: Real-Time Visual SLAM for Dynamic Environments Using Semantic Label Prediction With Optical Flow.â€ *IEEE Access*, vol. 9, 2021, pp. 106981â€“97. *IEEE Xplore*, https://doi.org/10.1109/ACCESS.2021.3100426.

  - [code](https://github.com/yubaoliu/RDS-SLAM.git
    ), video.

- Cheng Jiyu, et al. â€œ**Improving Visual Localization Accuracy in Dynamic Environments Based on Dynamic Region Removal.**â€ *IEEE Transactions on Automation Science and Engineering*, vol. 17, no. 3, July 2020, pp. 1585â€“96. *IEEE Xplore*, https://doi.org/10.1109/TASE.2020.2964938.

- Soares JoÃ£o Carlos Virgolino, et al. â€œ**[Crowd-SLAM: Visual SLAM Towards Crowded Environments Using Object Detection.](https://doi.org/10.1007/s10846-021-01414-1)**â€ *Journal of Intelligent & Robotic Systems* 2021

  - [code](https://github.com/virgolinosoares/Crowd-SLAM), video

- Kaveti Pushyami and Singh Hanumant. â€œ**[A Light Field Front-End for Robust SLAM in Dynamic Environments.](http://arxiv.org/abs/2012.10714)**â€.

- Kuen-Han Lin and Chieh-Chih Wang. â€œ**[Stereo-Based Simultaneous Localization, Mapping and Moving Object Tracking.](https://doi.org/10.1109/IROS.2010.5649653)**â€ IROS 2010

- Fu, H.; Xue, H.; Hu, X.; Liu, B. **[LiDAR Data Enrichment by Fusing Spatial and Temporal Adjacent Frames](https://doi.org/10.3390/rs13183640)**. *Remote Sens.* **2021**, *13*, 3640. 

- Qian, Chenglong, et al. ***RF-LIO: Removal-First Tightly-Coupled Lidar Inertial Odometry in High Dynamic Environments***. p. 8. IROS2021, **XJTU**

- K. Minoda, F. Schilling, V. WÃ¼est, D. Floreano, and T. Yairi, â€œ**[VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments,](https://doi.org/10.1109/LRA.2021.3058073)**â€RAL 2021

  - åŠ¨æ€ç¯å¢ƒçš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬äº†é™æ€ï¼ŒåŠ¨æ€ç­‰çº§çš„åœºæ™¯ï¼Œæ„Ÿè§‰é€‚åˆç”¨æ¥ä½œä¸ºéªŒè¯ã€‚
  - ä¸œäº¬å¤§å­¦ï¼Œ[code](https://github.com/kminoda/VIODE)
  
- W. Dai, Y. Zhang, P. Li, Z. Fang, and S. Scherer, â€œ**[RGB-D SLAM in Dynamic Environments Using Point Correlations](https://doi.org/10.1109/TPAMI.2020.3010942)**,â€ *IEEE Transactions on Pattern Analysis and Machine Intelligence*, pp. 1â€“1, 2020

  - æµ™å¤§ï¼Œä½¿ç”¨ç‚¹çš„å…³è”è¿›è¡Œå»é™¤ã€‚

- C. Huang, H. Lin, H. Lin, H. Liu, Z. Gao, and L. Huang, â€œYO-VIO: Robust Multi-Sensor Semantic Fusion Localization in Dynamic Indoor Environments,â€ in 2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN), 2021.
  - ä½¿ç”¨yoloå’Œå…‰æµå¯¹è¿åŠ¨å¯¹è±¡è¿›è¡Œåˆ¤æ–­ï¼Œå»é™¤ç‰¹å¾ç‚¹åè¿›è¡Œå®šä½
  - VIOçš„ç»“åˆ

- Dynamic-VINSï¼šRGB-D Inertial Odometry for a Resource-restricted Robot in Dynamic Environments. 
  - åˆ†å‰²+è¿åŠ¨ç‚¹ç½®ä¿¡åº¦ï¼Œ[code](https://github.com/HITSZ-NRSL/Dynamic-VINS),[video](https://www.bilibili.com/video/BV1bF411t7mx)



## Dynamic Object Detection and ***Tracking***

- â€œ**[AirDOS: Dynamic SLAM benefits from Articulated Objects,](http://arxiv.org/abs/2109.09903)**â€ Qiu Yuheng, et al. 2021(Arxiv)
  - [code](https://github.com/haleqiu/airdos)(TBA), [Paper](https://arxiv.org/abs/2109.09903), Video. **CMU RI**, Vision.
  
- â€œ[**DOT: Dynamic Object Tracking for Visual SLAM**](http://arxiv.org/abs/2010.00052).â€ Ballester, Irene, et al.(ICRA 2021)
  - code, [video](https://youtu.be/9hWChyQGKJk), **University of Zaragoza**, Vision
  
- Liu Yubao and Miura Jun. â€œ[**RDMO-SLAM: Real-Time Visual SLAM for Dynamic Environments Using Semantic Label Prediction With Optical Flow**](https://doi.org/10.1109/ACCESS.2021.3100426).â€ *IEEE Access*. 

- Kim Aleksandr, et al. â€œ[**EagerMOT: 3D Multi-Object Tracking via Sensor Fusion.**](http://arxiv.org/abs/2104.14682)â€ (*ICRA 2021*)
  - **TUM**, [code](https://github.com/aleksandrkim61/EagerMOT), [video](https://youtu.be/k8pKpvbenoM), Sensor Fusion.
  
- 1. Shan, Mo, et al. â€œ**[OrcVIO: Object Residual Constrained Visual-Inertial Odometry.](http://moshan.cf/orcvio_githubpage/0072.pdf)**â€ *(IROS2020)*
  2. Shan, Mo, et al. â€œ**[OrcVIO: Object Residual Constrained Visual-Inertial Odometry.](http://arxiv.org/abs/2007.15107)**â€ (IROS 2021)

  - [code](https://github.com/shanmo/OrcVIO), [video](http://moshan.cf/orcvio_githubpage/), [Project page](http://moshan.cf/orcvio_githubpage/).

- Rosen, David M., et al. â€œ[**Towards Lifelong Feature-Based Mapping in Semi-Static Environments.**](https://doi.org/10.1109/ICRA.2016.7487237)â€ *(ICRA 2016)*

- 1. Henein Mina, et al. â€œ[**Dynamic SLAM: The Need For Speed**](https://arxiv.org/abs/2002.08584v2).â€ *(ICRA 2020)*
  2. Zhang Jun, et al. â€œ**[VDO-SLAM: A Visual Dynamic Object-Aware SLAM System](http://arxiv.org/abs/2005.11052)**.â€ (ArXiv 2020)
  3. **[Robust Ego and Object 6-DoF Motion Estimation and Tracking](https://arxiv.org/abs/2007.13993v1)**,Jun Zhang, Mina Henein, Robert Mahony and Viorela Ila. IROS 2020([code](https://github.com/halajun/multimot_track))

  - [code](https://github.com/halajun/VDO_SLAM), [video](https://drive.google.com/file/d/1PbL4KiJ3sUhxyJSQPZmRP6mgi9dIC0iu/view), Vision
  
- Minoda, Koji, et al. â€œ**[VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments.](https://arxiv.org/abs/2102.05965v1)**â€ (RAL 2021)

  - [**code_and dataset**](https://github.com/kminoda/VIODE), [video](https://youtu.be/LlFTyQf_dlo).

- Vincent, Jonathan, et al. â€œ[**Dynamic Object Tracking and Masking for Visual SLAM.**](https://arxiv.org/abs/2008.00072v1)â€, (IROS 2020)

  - [code](https://github.com/introlab/dotmask), video, 

- Huang, Jiahui, et al. â€œ**[ClusterVO: Clustering Moving Instances and Estimating Visual Odometry for Self and Surroundings](http://arxiv.org/abs/2003.12980)**.â€ (CVPR 2020)

  - Tsinghua, code, [video](https://youtu.be/paK-WCQpX-Y).[slides](https://cg.cs.tsinghua.edu.cn/people/~huangjh/clustervo-slides.pdf).

- Liu, Yuzhen, et al. â€œ**[A Switching-Coupled Backend for Simultaneous Localization and Dynamic Object Tracking.](https://github.com/zhuhu00/Awesome_Dynamic_SLAM/raw/main/pdfs/liu_2021_SwitchingCoupled.pdf)**â€ (RAL 2021)

  - Tsinghua

- Yang Charig, et al. â€œ**[Self-Supervised Video Object Segmentation by Motion Grouping](http://arxiv.org/abs/2104.07658)**.â€(ICCV 2021)

  - [Project page](https://charigyang.github.io/motiongroup/).

- Long Ran, et al. â€œ**[RigidFusion: Robot Localisation and Mapping in Environments with Large Dynamic Rigid Objects](http://arxiv.org/abs/2010.10841)**.â€ ,(RAL 2021)

  - [**project page**](https://conferences.inf.ed.ac.uk/rigidfusion/).code, video, 

- Yang Bohong, et al. â€œ**[Multi-Classes and Motion Properties for Concurrent Visual SLAM in Dynamic Environments.](https://doi.org/10.1109/TMM.2021.3110667)**â€ *IEEE Transactions on Multimedia*, 2021

- Yang Gengshan and Ramanan Deva. â€œ**[Learning to Segment Rigid Motions from Two Frames.](http://arxiv.org/abs/2101.03694)**â€ CVPR 2021

  - [Project page](https://www.contrib.andrew.cmu.edu/~gengshay/cvpr21rigidmask.html).

- Thomas Hugues, et al. â€œ**[Learning Spatiotemporal Occupancy Grid Maps for Lifelong Navigation in Dynamic Scenes.](http://arxiv.org/abs/2108.10585)**â€ 

  - [code](https://github.com/utiasASRL/Deep-Collison-Checker).

- Jung Dongki, et al. â€œ**[DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes.](http://arxiv.org/abs/2108.05615)**â€ (ICCV 2021)

  - code, video.
  
- Luiten Jonathon, et al. â€œ[**Track to Reconstruct and Reconstruct to Track.**](https://arxiv.org/abs/1910.00130v3)â€, (RAL+ICRA 2020)

  - [code](https://github.com/tobiasfshr/MOTSFusion), [video](https://youtu.be/PMOYkpBwE78). **Reconstruct**.

- Grinvald, Margarita, et al. â€œ**[TSDF++: A Multi-Object Formulation for Dynamic Object Tracking and Reconstruction.](http://arxiv.org/abs/2105.07468)**â€(ICRA 2021)

  - [code](https://github.com/ethz-asl/tsdf-plusplus), [video](https://youtu.be/dSJmoeVasI0).

- **Wang Chieh-Chih, et al. â€œ[Simultaneous Localization, Mapping and Moving Object Tracking.](https://www.ri.cmu.edu/pub_files/pub4/wang_chieh_chih_2007_1/wang_chieh_chih_2007_1.pdf)â€ *The International Journal of Robotics Research 2007***

- Ran Teng, et al. â€œ**[RS-SLAM: A Robust Semantic SLAM in Dynamic Environments Based on RGB-D Sensor](https://doi.org/10.1109/JSEN.2021.3099511)**.â€ 

- Xu Hua, et al. â€œOD-SLAM: Real-Time Localization and Mapping in Dynamic Environment through Multi-Sensor Fusion.â€ * (ICARM 2020)* https://doi.org/10.1109/ICARM49381.2020.9195374.

- Wimbauer Felix, et al. â€œ**[MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera.](http://arxiv.org/abs/2011.11814)**â€ (CVPR 2021)

  - **[Project page](https://vision.in.tum.de/research/monorec)**. [code](https://github.com/Brummi/MonoRec). [video](https://youtu.be/-gDSBIm0vgk). [video 2](https://youtu.be/-gDSBIm0vgk).

- Liu Yu, et al. â€œDynamic RGB-D SLAM Based on Static Probability and Observation Number.â€ *IEEE Transactions on Instrumentation and Measurement*, vol. 70, 2021, pp. 1â€“11. *IEEE Xplore*, https://doi.org/10.1109/TIM.2021.3089228.

- P. Li, T. Qin, and S. Shen, â€œ**[Stereo Vision-based Semantic 3D Object and Ego-motion Tracking for Autonomous Driving](http://arxiv.org/abs/1807.02062)**,â€ arXiv 2018

  - æ²ˆé‚µé¢‰è€å¸ˆç»„

- G. B. Nair *et al.*, â€œ**[Multi-object Monocular SLAM for Dynamic Environments](http://arxiv.org/abs/2002.03528)**,â€ IV2020

- M. RÃ¼nz and L. Agapito, â€œ[**Co-fusion: Real-time segmentation, tracking and fusion of multiple objects,**](https://doi.org/10.1109/ICRA.2017.7989518)â€ in *2017 IEEE International Conference on Robotics and Automation (ICRA)*, May 2017, pp. 4471â€“4478.

  - [code](https://github.com/martinruenz/co-fusion), 

- [TwistSLAM: Constrained SLAM in Dynamic Environment](https://arxiv.org/pdf/2202.12384),
  - S3LAMçš„åç»­ï¼Œä½¿ç”¨å…¨æ™¯åˆ†å‰²ä½œä¸ºæ£€æµ‹çš„å‰ç«¯



## Researchers

### ğŸ¥¼1. Berta Bescos

> **ä¸»é¡µï¼š[è°·æ­Œå­¦æœ¯](https://scholar.google.hk/citations?user=8koVpHwAAAAJ&hl=it) | [ä¸ªäººä¸»é¡µ](https://bertabescos.github.io/) | [GitHub](https://github.com/BertaBescos)**

> **åšå£«å­¦ä½è®ºæ–‡ï¼š [Visual slam in dynamic environments](https://zaguan.unizar.es/record/100672)**

> **ä»£è¡¨æ€§å·¥ä½œ**

- **[1]** Bescos B, FÃ¡cil J M, Civera J, et al. [DynaSLAM: Tracking, mapping, and inpainting in dynamic scenes](https://arxiv.org/pdf/1806.05620.pdf)[J]. IEEE Robotics and Automation Letters, **2018**, 3(4): 4076-4083.
- **[2]** Bescos B, Neira J, Siegwart R, et al. [Empty cities: Image inpainting for a dynamic-object-invariant space](https://arxiv.org/pdf/1809.10239.pdf)[C]//2019 International Conference on Robotics and Automation (ICRA). IEEE, **2019**: 5460-5466.
- **[3]** Bescos B, Cadena C, Neira J. [Empty cities: A dynamic-object-invariant space for visual SLAM](https://arxiv.org/pdf/2010.07646.pdf)[J]. IEEE Transactions on Robotics, **2020**, 37(2): 433-451.
- **[4]** Bescos B, Campos C, TardÃ³s J D, et al. [DynaSLAM II: Tightly-coupled multi-object tracking and SLAM](https://arxiv.org/pdf/2010.07820.pdf)[J]. IEEE Robotics and Automation Letters, **2021**, 6(3): 5191-5198.

### ğŸ¥¼2. Yubao Liu

[Walk Into AI World](https://www.ybliu.com/)

> ä¸»é¡µï¼š[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=P4M6ru0AAAAJ&hl=zh-CN) | [GitHub](https://github.com/yubaoliu)

> ä»£è¡¨æ€§å·¥ä½œï¼š

1. RDS-SLAM: real-time dynamic SLAM using semantic segmentation methods
2. KMOP-vSLAM: Dynamic Visual SLAM for RGB-D Cameras using K-means and OpenPose
3. RDMO-SLAM: Real-time Visual SLAM for Dynamic Environments using Semantic Label Prediction with Optical Flow
#### 3. Guoquan Huang(SLAMMOT)


#### 4. Shenshao Jie(MOT)
